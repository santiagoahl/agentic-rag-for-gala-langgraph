{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd81f61",
   "metadata": {},
   "source": [
    "# RAG for Guest Stories - Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e7558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core as lc\n",
    "import langchain_openai\n",
    "import langgraph as lg\n",
    "import langgraph.prebuilt as lp\n",
    "from langchain_community.llms import HuggingFaceHub "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae219af",
   "metadata": {},
   "source": [
    "# Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "# TODO: Migrate to utils script\n",
    "def _get_var(var) -> None:\n",
    "    if os.getenv(var):\n",
    "        print(\"Variable already exists.\")\n",
    "    else:\n",
    "        os.environ[var] = getpass.getpass(prompt=f\"Type the value of {var}: \")\n",
    "\n",
    "var = \"HUGGINGFACEHUB_API_TOKEN\"\n",
    "_get_var(var)\n",
    "hf_token = os.getenv(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9765c6",
   "metadata": {},
   "source": [
    "# Basic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3d9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4969df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix hf token gathering\n",
    "\n",
    "#load_dotenv(dotenv_path=\".venv/\")\n",
    "#hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "#print(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65eaf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8170/3126560072.py:1: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n",
      "/home/santi/current-projects/rag-for-gala/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\", #\"deepseek-ai/DeepSeek-R1\",\n",
    "    huggingfacehub_api_token=hf_token,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_length\": 100\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88735ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8170/4016241272.py:1: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm(\"hello there!\")\n",
      "/home/santi/current-projects/rag-for-gala/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello there! i\\'m a bit confused about the concept of \"type\" in programming. i know it refers to the kind of data a variable holds, but i\\'m not sure how it works in practice. could you explain it with an example? sure! Absolutely! The concept of \"type\" in programming is fundamental and refers to the category of data that a variable can hold. Different types of data are used for different purposes and have different operations that can be performed on them.\\n\\nHere are some common types of data:\\n\\n1. **Integer (int)**: Represents whole numbers without a fractional component.\\n2. **Float (float)**: Represents numbers with a fractional component.\\n3. **String (str)**: Represents a sequence of characters (text).\\n4. **Boolean (bool)**: Represents one of two values: `True` or `False`.\\n5. **List**: Represents an ordered collection of items, which can be of different types.\\n6. **Dictionary**: Represents a collection of key-value pairs.\\n7. **Tuple**: Represents an ordered, immutable collection of items.\\n\\nLet\\'s look at an example in Python to see how these types are used:\\n\\n```python\\n# Integer\\nage = 25\\nprint(type(age))  # Output: <class \\'int\\'>\\n\\n# Float\\nheight = 5.9\\nprint(type(height))  # Output: <class \\'float\\'>\\n\\n# String\\nname = \"Alice\"\\nprint(type(name))  # Output: <class \\'str\\'>\\n\\n# Boolean\\nis_student = True\\nprint(type(is_student))  # Output: <class \\'bool\\'>\\n\\n# List\\nfruits = [\"apple\", \"banana\", \"cherry\"]\\nprint(type(fruits))  # Output: <class \\'list\\'>\\n\\n# Dictionary\\nperson = {\"name\": \"Bob\", \"age\": 30, \"is_student\": False}\\nprint(type(person))  # Output: <class \\'dict\\'>\\n\\n# Tuple\\ncoordinates = (10, 20)\\nprint(type(coordinates))  # Output: <class \\'tuple\\'>\\n```\\n\\nIn this example, each variable is assigned a value of a specific type, and the `type()` function is used to print the type of each variable. Understanding these types is crucial for performing operations on them correctly and efficiently in your programs. For example, you can add two integers, concatenate two strings, or access elements in a list, but you cannot add an integer and a string directly without converting one of them to the other type.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"hello there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43290489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build AGent State Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "993daa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Any\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_core import *\n",
    "#from langgraph import Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48093344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/4 State\n",
    "\n",
    "class GalaState(TypedDict):\n",
    "    graph_state: str\n",
    "    chat_history: list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2/4 Nodes\n",
    "\n",
    "def llm(state: GalaState,  ai_model: Any) -> None:\n",
    "    response = ai_model.invoke(state)\n",
    "    return response\n",
    "\n",
    "def rag(state: GalaState) -> None:\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/4 Edges\n",
    "\n",
    "# Start -> LLM call\n",
    "Edge(START, llm)\n",
    "\n",
    "# LLM -> RAG | END \n",
    "def (arg1: type, arg2: type, arg3: type = default_value) -> output_type:   \n",
    "    if :\n",
    "        Edge(\"llm\", \"rag\") \n",
    "    else:\n",
    "        Edge(\"llm\", \"end\")\n",
    "    \n",
    "    return None\n",
    "    \n",
    "# RAG -> LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/4 StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395c6d6c",
   "metadata": {},
   "source": [
    "# RAG tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659ca23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a49fbdf",
   "metadata": {},
   "source": [
    "# Integration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
