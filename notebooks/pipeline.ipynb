{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd81f61",
   "metadata": {},
   "source": [
    "# RAG for Guest Stories - Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d7e7558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core as lc\n",
    "import langchain_openai\n",
    "import langgraph as lg\n",
    "import langgraph.prebuilt as lp\n",
    "from langchain_community.llms import HuggingFaceHub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a5c55a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.sys.path.append(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae219af",
   "metadata": {},
   "source": [
    "# Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c9a0b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable already exists.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "# TODO: Migrate to utils script\n",
    "def _get_var(var) -> None:\n",
    "    if os.getenv(var):\n",
    "        print(\"Variable already exists.\")\n",
    "    else:\n",
    "        os.environ[var] = getpass.getpass(prompt=f\"Type the value of {var}: \")\n",
    "\n",
    "var = \"HUGGINGFACEHUB_API_TOKEN\"\n",
    "_get_var(var)\n",
    "hf_token = os.getenv(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9765c6",
   "metadata": {},
   "source": [
    "# Basic Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2a3d9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, START, StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4969df61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix hf token gathering\n",
    "\n",
    "#load_dotenv(dotenv_path=\".venv/\")\n",
    "#hf_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "#print(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "43290489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build AGent State Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "993daa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Any\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_core import *\n",
    "from typing import Literal, TypedDict\n",
    "#from langgraph import Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "69dd8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0/4 import tools\n",
    "\n",
    "from tools import search_tool, weather_tool\n",
    "from rag import RAGTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "88e6893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "48093344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1/4 State\n",
    "\n",
    "class GalaState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    intermediate_steps: list\n",
    "    done: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "df7dc5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY successfully processed\n"
     ]
    }
   ],
   "source": [
    "# TODO: Migrate _get_var to utils script\n",
    "\n",
    "import getpass\n",
    "\n",
    "def _get_var(var) -> None:\n",
    "    if os.getenv(var):\n",
    "        print(f\"{var} successfully processed\")\n",
    "    else:\n",
    "        os.environ[var] = getpass.getpass(prompt=f\"Type the value of {var}: \")\n",
    "        \n",
    "_get_var(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "926e30b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d2fd82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2/4 Nodes\n",
    "from langchain_core.runnables import Runnable\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#def llm(state: GalaState,  ai_model: Any) -> None:\n",
    "#    response = ai_model.invoke(state)  # TODO: Process correctly the state\n",
    "#    return response \n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "tools = [RAGTool, weather_tool, search_tool]\n",
    "tools_node = ToolNode(tools)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "# Q: How to get the user query. What if he has another response? They must run a new agent call? does the agent forgets?\n",
    "def agent(state: GalaState) -> GalaState:   \n",
    "    textual_description = \"\"\"\n",
    "    LLM model. Reasons and observes the GalaState to make a decision or prompt a response.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : GalaState\n",
    "        Information about the chat. It has the following keys: graph_state, chat_history, next_node\n",
    "    \n",
    "    Returns:\n",
    "        type: GalaState\n",
    "    \n",
    "    Example:\n",
    "        >>> agent({\"messages\": \"Who is Batman\"})\n",
    "        Batman is a cool superhero\n",
    "    \"\"\"\n",
    "    chat_history = state.get(\"messages\", [])\n",
    "    \n",
    "    formatted_messages = [\n",
    "        {\"role\": \"user\" if msg.type == \"human\" else \"assistant\", \"content\": msg.content}\n",
    "        for msg in chat_history\n",
    "    ]\n",
    "    response = model_with_tools.invoke(input=formatted_messages)\n",
    "    \n",
    "    result = {\n",
    "        \"messages\": state.get(\"messages\", []) + [response]\n",
    "    }\n",
    "    \n",
    "    # Handle tool calls if they exist\n",
    "    if hasattr(response, \"tool_calls\") and response.tool_calls:\n",
    "        # This will trigger the tool execution in LangGraph\n",
    "        return {\"messages\": chat_history + [response]}\n",
    "    \n",
    "    # For regular responses\n",
    "    return {\n",
    "        \"messages\": chat_history + [response],\n",
    "        **{k: v for k, v in state.items() if k != \"messages\"}  # Preserve other state\n",
    "    }\n",
    "\n",
    "#agent_model = Runnable(llm)\n",
    "#agent_node = Runnable(agent_tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ba2f6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/4 Edges\n",
    "\n",
    "\n",
    "# Start -> LLM call\n",
    "#Edge(START, llm)\n",
    "\n",
    "# LLM -> Tools | END \n",
    "def should_use_tool(state: GalaState) -> Literal[\"tools\", \"end\"]:  \n",
    "    \"\"\"\"\n",
    "    Determine whether to use tools based on the agent's last response\n",
    "    \"\"\"\n",
    "    \n",
    "    last_message = state.get(\"messages\", [])[-1]\n",
    "    \n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        next_node = \"tools\" \n",
    "    else: \n",
    "        next_node = \"end\"  \n",
    "        \n",
    "    return next_node\n",
    "    \n",
    "# Tools -> LLM\n",
    "#EDGE(\"tools\", \"llm\")\n",
    "\n",
    "#EDGE(\"llm\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "532a3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3/4 Build the graph\n",
    "\n",
    "builder = StateGraph(state_schema=GalaState)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"agent\", agent)\n",
    "builder.add_node(\"tools\", tools_node)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_use_tool,\n",
    "    {\"tools\": \"tools\", \"end\": END}\n",
    ")\n",
    "builder.add_edge(\"tools\", \"agent\") # Agent processes tool results\n",
    "builder.add_edge(\"agent\", END) # Define a direct edge to END after the agent runs (either initially or after tools)\n",
    "\n",
    "agent_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c9d90b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4/4 Visualize\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(agent_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49fbdf",
   "metadata": {},
   "source": [
    "# Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e06d0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"Hi. Tell me please Who is Ada and Which will be the story to tell about she?\"\n",
    "prompt_2 = \"Hi. Tell me please Which was the result of the match Barcelona vs Inter today for the 24/25 Champions League Semifinal\"\n",
    "prompt_3 = \"Hi. Tell me please how's the weather today at Barcelona\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "328d62df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tools:WEATHER_API_KEY successfully processed\n",
      "INFO:tools:WEATHER_API_KEY successfully processed\n",
      "INFO:tools:WEATHER_API_KEY successfully processed\n",
      "INFO:tools:WEATHER_API_KEY successfully processed\n",
      "INFO:tools:WEATHER_API_KEY successfully processed\n",
      "INFO:tools:WEATHER_API_KEY successfully processed\n",
      "INFO:tools:WEATHER_API_KEY successfully processed\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response_1 \u001b[38;5;241m=\u001b[39m \u001b[43magent_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/current-projects/rag-agent-for-gala-hf/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2804\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2801\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2802\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2804\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2805\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2806\u001b[0m     config,\n\u001b[1;32m   2807\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2808\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2809\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2810\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2811\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[1;32m   2812\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2813\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2814\u001b[0m ):\n\u001b[1;32m   2815\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2816\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2817\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2818\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m         ):\n",
      "File \u001b[0;32m~/current-projects/rag-agent-for-gala-hf/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2461\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2453\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m   2454\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   2455\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2459\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[1;32m   2460\u001b[0m     )\n\u001b[0;32m-> 2461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[1;32m   2462\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   2463\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "response_1 = agent_graph.invoke({\"messages\": [HumanMessage(content=prompt_1)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c947f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55698d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_2 = agent_graph.invoke({\"messages\": [HumanMessage(prompt_2)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a0b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_3 = agent_graph.invoke({\"messages\": [HumanMessage(prompt_3)]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a3787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
